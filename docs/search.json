[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Traitement d‚Äôimages satellites avec Python",
    "section": "",
    "text": "Pr√©face",
    "crumbs": [
      "Pr√©face"
    ]
  },
  {
    "objectID": "index.html#sect001",
    "href": "index.html#sect001",
    "title": "Traitement d‚Äôimages satellites avec Python",
    "section": "Un manuel sous la forme d‚Äôune ressource √©ducative libre",
    "text": "Un manuel sous la forme d‚Äôune ressource √©ducative libre\nPourquoi un manuel sous licence libre?\nLes logiciels libres sont aujourd‚Äôhui tr√®s r√©pandus. Comparativement aux logiciels propri√©taires, l‚Äôacc√®s au code source permet √† quiconque de l‚Äôutiliser, de le modifier, de le dupliquer et de le partager. Le logiciel Python, dans lequel sont mises en ≈ìuvre les m√©thodes de traitement d‚Äôimages satellites d√©crites dans ce livre, est d‚Äôailleurs √† la fois un langage de programmation et un logiciel libre (sous la licence publique g√©n√©rale GNU GPL2). Par analogie aux logiciels libres, il existe aussi des ressources √©ducatives libres (REL) ¬´¬†dont la licence accorde les permissions d√©sign√©es par les 5R (Retenir ‚Äî R√©utiliser ‚Äî R√©viser ‚Äî Remixer ‚Äî Redistribuer) et donc permet n√©cessairement la modification¬†¬ª (fabriqueREL). La licence de ce livre, CC BY-SA (figure¬†1), permet donc de¬†:\n\nRetenir, c‚Äôest-√†-dire t√©l√©charger et imprimer gratuitement le livre. Notez qu‚Äôil aurait √©t√© plut√¥t surprenant d‚Äô√©crire un livre payant sur un logiciel libre et donc gratuit. Aussi, nous aurions √©t√© tr√®s embarrass√©s que des personnes √©tudiantes avec des ressources financi√®res limit√©es doivent payer pour avoir acc√®s au livre, sans pour autant savoir pr√©alablement si le contenu est r√©ellement adapt√© √† leurs besoins.\nR√©utiliser, c‚Äôest-√†-dire utiliser la totalit√© ou une section du livre sans limitation et sans compensation financi√®re. Cela permet ainsi √† d‚Äôautres personnes enseignantes de l‚Äôutiliser dans le cadre d‚Äôactivit√©s p√©dagogiques.\nR√©viser, c‚Äôest-√†-dire modifier, adapter et traduire le contenu en fonction d‚Äôun besoin p√©dagogique pr√©cis puisqu‚Äôaucun manuel n‚Äôest parfait, tant s‚Äôen faut! Le livre a d‚Äôailleurs √©t√© √©crit int√©gralement dans R avec Quatro. Quiconque peut ainsi t√©l√©charger gratuitement le code source du livre sur github et le modifier √† sa guise (voir l‚Äôencadr√© intitul√© Suggestions d‚Äôadaptation du manuel).\nRemixer, c‚Äôest-√†-dire ¬´¬†combiner la ressource avec d‚Äôautres ressources dont la licence le permet aussi pour cr√©er une nouvelle ressource int√©gr√©e¬†¬ª (fabriqueREL).\nRedistribuer, c‚Äôest-√†-dire distribuer, en totalit√© ou en partie le manuel ou une version r√©vis√©e sur d‚Äôautres canaux que le site Web du livre (par exemple, sur le site Moodle de votre universit√© ou en faire une version imprim√©e).\n\nLa licence de ce livre, CC BY-SA (figure¬†1), oblige donc √†¬†:\n\nAttribuer la paternit√© de l‚Äôauteur dans vos versions d√©riv√©es, ainsi qu‚Äôune mention concernant les grandes modifications apport√©es, en utilisant la formulation suivante¬†:\n\nApparicio Philippe, Yacine Bouroubi, Samuel Foucher et Micka√´l Foucher (2024). Traitement d‚Äôimages satellites : . Universit√© de Sherbrooke, D√©partement de g√©omatique appliqu√©e. fabriqueREL. Licence CC¬†BY-SA.\n\nUtiliser la m√™me licence ou une licence similaire √† toutes versions d√©riv√©es.\n\n\n\n\n\n\n\nFigure¬†1: Licence Creative Commons du livre\n\n\n\n\n\n\n\n\nSuggestions d‚Äôadaptation du manuel\n\n\nPour chaque m√©thode d‚Äôanalyse spatiale abord√©e dans le livre, une description d√©taill√©e et une mise en ≈ìuvre dans Python sont disponibles. Par cons√©quent, plusieurs adaptations du manuel sont possibles¬†:\n\nConserver uniquement les chapitres sur les m√©thodes cibl√©es dans votre cours.\nEn faire une version imprim√©e et la distribuer aux personnes √©tudiantes.\nModifier la description d‚Äôune ou de plusieurs m√©thodes en effectuant les mises √† jour directement dans les chapitres.\nIns√©rer ses propres jeux de donn√©es dans les sections intitul√©es Mise en ≈ìuvre dans Python.\nModifier les tableaux et figures.\nAjouter une s√©rie d‚Äôexercices.\nModifier les quiz de r√©vision.\nR√©diger un nouveau chapitre.\nModifier des syntaxes en Python. Plusieurs librairies Python peuvent √™tre utilis√©es pour mettre en ≈ìuvre telle ou telle m√©thode. Ces derniers √©voluent aussi tr√®s vite et de nouvelles librairies sont propos√©es fr√©quemment! Par cons√©quent, il peut √™tre judicieux de modifier une syntaxe Python du livre en fonction de ses habitudes de programmation en Python (utilisation d‚Äôautres librairies que ceux utilis√©s dans le manuel par exemple) ou de bien mettre √† jour une syntaxe √† la suite de la parution d‚Äôune nouvelle librairie plus performante ou int√©ressante.\nToute autre adaptation qui permet de r√©pondre au mieux √† un besoin p√©dagogique.",
    "crumbs": [
      "Pr√©face"
    ]
  },
  {
    "objectID": "index.html#sect002",
    "href": "index.html#sect002",
    "title": "Traitement d‚Äôimages satellites avec Python",
    "section": "Comment lire ce manuel?",
    "text": "Comment lire ce manuel?\nLe livre comprend plusieurs types de blocs de texte qui en facilitent la lecture.\n\n\n\n\n\nBloc packages\n\n\nHabituellement localis√© au d√©but d‚Äôun chapitre, il comprend la liste des packages Python utilis√©s pour un chapitre.\n\n\n\n\n\n\n\nBloc objectif\n\n\nIl comprend une description des objectifs d‚Äôun chapitre ou d‚Äôune section.\n\n\n\n\n\n\n\nBloc notes\n\n\nIl comprend une information secondaire sur une notion, une id√©e abord√©e dans une section.\n\n\n\n\n\n\n\nBloc pour aller plus loin\n\n\nIl comprend des r√©f√©rences ou des extensions d‚Äôune m√©thode abord√©e dans une section.\n\n\n\n\n\n\n\nBloc astuce\n\n\nIl d√©crit un √©l√©ment qui vous facilitera la vie¬†: une propri√©t√© statistique, un package, une fonction, une syntaxe Python.\n\n\n\n\n\n\n\nBloc attention\n\n\nIl comprend une notion ou un √©l√©ment important √† bien ma√Ætriser.\n\n\n\n\n\n\n\nBloc exercice\n\n\nIl comprend un court exercice de r√©vision √† la fin de chaque chapitre.",
    "crumbs": [
      "Pr√©face"
    ]
  },
  {
    "objectID": "index.html#sect003",
    "href": "index.html#sect003",
    "title": "Traitement d‚Äôimages satellites avec Python",
    "section": "Comment utiliser les donn√©es du livre pour reproduire les exemples?",
    "text": "Comment utiliser les donn√©es du livre pour reproduire les exemples?\nCe livre comprend des exemples d√©taill√©s et appliqu√©s dans R pour chacune des m√©thodes abord√©es. Ces exemples se basent sur des jeux de donn√©es structur√©s et mis √† disposition avec le livre. Ils sont disponibles sur le repo github dans le sous-dossier data, √† l‚Äôadresse https://github.com/SerieBoldR/TraitementImagesVol1/tree/main/data.\nUne autre option est de t√©l√©charger le repo complet du livre directement sur github (https://github.com/SerieBoldR/TraitementImagesVol1) en cliquant sur le bouton Code, puis le bouton Download ZIP (figure¬†2.1). Les donn√©es se trouvent alors dans le sous-dossier nomm√© data.\n\n\n\n\n\n\nFigure¬†2: T√©l√©chargement de l‚Äôint√©gralit√© du livre",
    "crumbs": [
      "Pr√©face"
    ]
  },
  {
    "objectID": "index.html#sect004",
    "href": "index.html#sect004",
    "title": "Traitement d‚Äôimages satellites avec Python",
    "section": "Structure du livre",
    "text": "Structure du livre\nLe livre est organis√© autour de quatre grandes parties.\nPartie 1. Importation et manipulation de donn√©es spatiales. Dans cette premi√®re partie, nous voyons comment importer, manipuler, cartographier et exporter des donn√©es spatiales dans R, principalement avec les packages sf pour les donn√©es vectorielles, terra pour les donn√©es matricielles (images) et tmap pour la cartographie (chapitre¬†2¬† Importation et manipulation de donn√©es spatiales). Ma√Ætriser les notions abord√©es dans ce chapitre constitue une √©tape pr√©alable et indispensable √† tout projet d‚Äôanalyse spatiale. D‚Äôune part, avant d‚Äôanalyser des donn√©es spatiales, il convient de les structurer (importation et manipulation) et de les explorer (cartographie). D‚Äôautre part, une fois la ou les m√©thodes d‚Äôanalyse spatiale mises en ≈ìuvre, il convient de cartographier les r√©sultats finaux et de les exporter au besoin dans un format de donn√©es g√©ographiques (shapefile (shp), GeoPackage (GPKG), GeoJSON (geojson), sqlite (sqlite), GeoTiff, etc.).\nPartie 2. Transformations des donn√©es spatiales. Cette troisi√®me partie comprend deux chapitres¬†: les transformations spectrales (?sec-chap03) et les transformations spatiales (?sec-chap04).\nPartie 3. Classifications d‚Äôimages. Cette troisi√®me partie comprend deux chapitres¬†: les classifications supervis√©es (?sec-chap05) et non supervis√©es (?sec-chap06).\nPartie 4. Donn√©es massives. Cette quatri√®me et derni√®re partie comprend un seul chapitre qui est d√©di√© aux plateformes de m√©gadonnes ?sec-chap07, notammment Google Earth Engine.",
    "crumbs": [
      "Pr√©face"
    ]
  },
  {
    "objectID": "index.html#sect005",
    "href": "index.html#sect005",
    "title": "Traitement d‚Äôimages satellites avec Python",
    "section": "Remerciements",
    "text": "Remerciements\nDe nombreuses personnes ont contribu√© √† l‚Äô√©laboration de ce manuel.\nCe projet a b√©n√©fici√© du soutien p√©dagogique et financier de la fabriqueREL (ressources √©ducatives libres). Les diff√©rentes rencontres avec le comit√© de suivi nous ont permis de comprendre l‚Äôunivers des ressources √©ducatives libres (REL) et notamment leurs fameux 5R (Retenir ‚Äî R√©utiliser ‚Äî R√©viser ‚Äî Remixer ‚Äî Redistribuer), de mieux d√©finir le besoin p√©dagogique vis√© par ce manuel, d‚Äôidentifier des ressources p√©dagogiques et des outils pertinents pour son √©laboration. Ainsi, nous remercions chaleureusement les membres de la fabriqueREL pour leur soutien inconditionnel¬†:\n\nMyriam Beaudet, biblioth√©caire √† l‚ÄôUniversit√© de Sherbrooke.\nMarianne Dub√©, coordonnatrice de la fabriqueREL, Universit√© de Sherbrooke.\nSerge Pich√©, conseiller p√©dagogique, Universit√© de Sherbrooke.\nClaude Potvin, conseiller en formation, Service de soutien √† l‚Äôenseignement, Universit√© Laval.\n\nNous remercions chaleureusement les personnes √©tudiantes des cours √† modifier plus tard du Baccalaur√©at en g√©omatique appliqu√©e √† l‚Äôenvironnement et du Microprogramme de 1er cycle en g√©omatique appliqu√©e du D√©partement de g√©omatique appliqu√©e de l‚ÄôUniversit√© de Sherbrooke de la session d‚Äô√©t√© 2023¬†: √† modifier plus tard.\nNous remercions aussi les membres du comit√© de r√©vision pour leurs commentaires et suggestions tr√®s constructifs. Ce comit√© est compos√© de quatre personnes √©tudiantes du D√©partement de g√©omatique appliqu√©e de l‚ÄôUniversit√© de Sherbrooke¬†:\n\n√Ä compl√©ter plus tard.\n√Ä compl√©ter plus tard.\n\nFinalement, nous remercions Denise Latreille, r√©viseure linguistique et charg√©e de cours √† l‚ÄôUniversit√© Sherbrooke, pour la r√©vision du manuel.",
    "crumbs": [
      "Pr√©face"
    ]
  },
  {
    "objectID": "index.html#sect006",
    "href": "index.html#sect006",
    "title": "Traitement d‚Äôimages satellites avec Python",
    "section": "Introduction aux images de t√©l√©d√©tection",
    "text": "Introduction aux images de t√©l√©d√©tection\nL‚Äôimagerie num√©rique a pris une place importante dans notre vie de tous les jours depuis une quinzaine d‚Äôann√©e. Ces images sont prises g√©n√©ralement au niveau du sol (imagerie proximale) avec seulement trois couleurs dans le domaine de la vision humaine (rouge, vert et bleu). Dans la suite du manuel, on parlera d‚Äôimages du domaine de la vision par ordinateur ou images en vision pour faire plus court.\nLes images de t√©l√©d√©tection ont des particularit√©s et des propri√©t√©s qui les diff√©rencient des images de tous les jours. On peut souligner au moins cinq caract√©ristiques principales: 1. Les images sont g√©or√©f√©renc√©es : Cela veut dire que pour chaque pixel nous pouvons y associer une position g√©ographique ou cartographique. 2. Le point de vue est tr√®s diff√©rent : Ces images sont prises avec une vue d‚Äôen haut (Nadir) ou oblique avec une distance qui peut √™tre tr√®s grande (On parle d‚Äôimages distales). 3. Elles poss√®dent plus que 3 bandes : Contrairement aux images en vision, les images de t√©l√©d√©tection poss√®dent bien souvent plus que 3 bandes. Il n‚Äôest pas rare de trouver 4 bandes (Pl√©iade), 13 bandes (Sentinel-2, Landsat) et m√™me 200 bandes pour des capteurs hyperspectraux. 4. Elles peuvent √™tre calibr√©es : Les valeurs num√©rique de l‚Äôimage peuvent √™tre converties en quantit√©s physiques (luminance, r√©flectance, section efficiace, etc.) via une fonction de calibration. 5. Elles sont de grande taille : Il n‚Äôest pas rare de manipuler des images qui font plusieurs dizaines de milliers de pixels en dimension.\n\nRessources en ligne\n\n\nListes des librairies utilis√©s\nDans ce livre, nous utilisons de nombreux packages Python que vous pouvez installer avec le code ci-dessous.\n\nimport sys\nimport subprocess\nimport pkg_resources\n\n# Liste des packages\nlist_packages = [\"pandas\", \"scikit-image\", \"matplotlib\", \n                 \"geopandas\", \"rasterio\", \"folium\"]\n\n# Packages non install√©s dans la liste\ninstalled_packages = {pkg.key for pkg in pkg_resources.working_set}\npackages_not_installed = [pkg for pkg in list_packages if pkg.lower() not in installed_packages]\n\n# Installation des packages manquants\nif packages_not_installed:\n    print(\"Installing missing packages...\")\n    for package in packages_not_installed:\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n    print(\"All packages installed successfully.\")\nelse:\n    print(\"All required packages are already installed.\")\n\n\n\nPython 101\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\nFigure¬†3: A line plot on a polar axis",
    "crumbs": [
      "Pr√©face"
    ]
  },
  {
    "objectID": "00-auteurs.html",
    "href": "00-auteurs.html",
    "title": "√Ä propos des auteurs",
    "section": "",
    "text": "Philippe Apparicio est professeur titulaire au D√©partement de g√©omatique appliqu√©e de l‚ÄôUniversit√© de Sherbrooke. Il y enseigne aux programmes de 1er et 2e cycles de g√©omatique les cours Transport et mobilit√© durable, Mod√©lisation et analyse spatiale et G√©omatique appliqu√©e √† la gestion urbaine. Durant les derni√®res ann√©es, il a offert plusieurs formations aux √âcoles d‚Äô√©t√© du Centre interuniversitaire qu√©b√©cois de statistiques sociales (CIQSS). G√©ographe de formation, ses int√©r√™ts de recherche incluent la justice et l‚Äô√©quit√© environnementale, la mobilit√© durable, les pollutions atmosph√©rique et sonore, et le v√©lo en ville. Il a publi√© une centaine d‚Äôarticles scientifiques dans diff√©rents domaines des √©tudes urbaines et de la g√©ographie mobilisant la g√©omatique et l‚Äôanalyse spatiale.\nYacine Bouroubi est professeur titulaire au D√©partement de g√©omatique appliqu√©e de l‚ÄôUniversit√© de Sherbrooke. Il y enseigne aux programmes de 1er et 2e cycles de g√©omatique les cours Transport et mobilit√© durable, Mod√©lisation et analyse spatiale et G√©omatique appliqu√©e √† la gestion urbaine. Durant les derni√®res ann√©es, il a offert plusieurs formations aux √âcoles d‚Äô√©t√© du Centre interuniversitaire qu√©b√©cois de statistiques sociales (CIQSS). G√©ographe de formation, ses int√©r√™ts de recherche incluent la justice et l‚Äô√©quit√© environnementale, la mobilit√© durable, les pollutions atmosph√©rique et sonore, et le v√©lo en ville. Il a publi√© une centaine d‚Äôarticles scientifiques dans diff√©rents domaines des √©tudes urbaines et de la g√©ographie mobilisant la g√©omatique et l‚Äôanalyse spatiale.\nSamuel Foucher est professeur titulaire au D√©partement de g√©omatique appliqu√©e de l‚ÄôUniversit√© de Sherbrooke. Il y enseigne aux programmes de 1er et 2e cycles de g√©omatique les cours Transport et mobilit√© durable, Mod√©lisation et analyse spatiale et G√©omatique appliqu√©e √† la gestion urbaine. Durant les derni√®res ann√©es, il a offert plusieurs formations aux √âcoles d‚Äô√©t√© du Centre interuniversitaire qu√©b√©cois de statistiques sociales (CIQSS). G√©ographe de formation, ses int√©r√™ts de recherche incluent la justice et l‚Äô√©quit√© environnementale, la mobilit√© durable, les pollutions atmosph√©rique et sonore, et le v√©lo en ville. Il a publi√© une centaine d‚Äôarticles scientifiques dans diff√©rents domaines des √©tudes urbaines et de la g√©ographie mobilisant la g√©omatique et l‚Äôanalyse spatiale.\nMicka√´l Germain est professeur titulaire au D√©partement de g√©omatique appliqu√©e de l‚ÄôUniversit√© de Sherbrooke. Il y enseigne aux programmes de 1er et 2e cycles de g√©omatique les cours Transport et mobilit√© durable, Mod√©lisation et analyse spatiale et G√©omatique appliqu√©e √† la gestion urbaine. Durant les derni√®res ann√©es, il a offert plusieurs formations aux √âcoles d‚Äô√©t√© du Centre interuniversitaire qu√©b√©cois de statistiques sociales (CIQSS). G√©ographe de formation, ses int√©r√™ts de recherche incluent la justice et l‚Äô√©quit√© environnementale, la mobilit√© durable, les pollutions atmosph√©rique et sonore, et le v√©lo en ville. Il a publi√© une centaine d‚Äôarticles scientifiques dans diff√©rents domaines des √©tudes urbaines et de la g√©ographie mobilisant la g√©omatique et l‚Äôanalyse spatiale.",
    "crumbs": [
      "√Ä propos des auteurs"
    ]
  },
  {
    "objectID": "00-PriseEnMainPython.html",
    "href": "00-PriseEnMainPython.html",
    "title": "1¬† Introduction au langage Python",
    "section": "",
    "text": "1.1 Les distributions\nIl existe plusieurs distributions du langage Python, ces distributions sont comme diff√©rentes saveurs de votre glace pr√©f√©r√©e - chacune a ses propres caract√©ristiques uniques, mais elles sont toutes fondamentalement Python. Voici un aper√ßu des principales distributions :\nJython et IronPython : Ces versions sont comme des traducteurs, permettant √† Python de ‚Äúparler‚Äù Java (Jython) ou .NET (IronPython). Chaque distribution a ses forces, que ce soit la simplicit√©, la vitesse ou des fonctionnalit√©s sp√©cifiques. Le choix d√©pend de vos besoins, comme choisir entre une glace simple ou un banana split √©labor√©.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction au langage Python</span>"
    ]
  },
  {
    "objectID": "00-PriseEnMainPython.html#les-distributions",
    "href": "00-PriseEnMainPython.html#les-distributions",
    "title": "1¬† Introduction au langage Python",
    "section": "",
    "text": "CPython : C‚Äôest la distribution ‚Äúvanille‚Äù officielle, comme la recette originale de Python. C‚Äôest le choix id√©al pour la compatibilit√© et la conformit√© aux standards.\nAnaconda : Pensez-y comme √† un sundae tout garni. Il vient avec de nombreuses biblioth√®ques scientifiques pr√©install√©es, id√©al pour l‚Äôanalyse de donn√©es et le machine learning.\nMiniconda : est une distribution l√©g√®re de Python qui vous permet d‚Äôajouter les librairies au besoin.\nPyPy : C‚Äôest comme une version turbo de Python, optimis√©e pour la vitesse.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction au langage Python</span>"
    ]
  },
  {
    "objectID": "00-PriseEnMainPython.html#les-styles-de-programmation-en-python",
    "href": "00-PriseEnMainPython.html#les-styles-de-programmation-en-python",
    "title": "1¬† Introduction au langage Python",
    "section": "1.2 Les styles de programmation en Python",
    "text": "1.2 Les styles de programmation en Python\nIl existe plusieurs approches pour programmer en Python. La plus directe est en version interactive en tapant python et de rentrer des commandes ligne par ligne.\n\n1.2.1 Les outils de programmation\nUn code python prend la forme d‚Äôun simple fichier texte avec l‚Äôextension .py et peut √™tre modifi√© avec un simple √©diteur de texte. Cependnant, il n‚Äôy aura pas de r√©troactions imm√©diates de l‚Äôinterpr√©teur Python ce qui rend la correction d‚Äôerreurs (d√©bogage) beaucoup plus laborieux.\nUn IDE (Integrated Developement Environnement) est comme une bo√Æte √† outils compl√®te pour les programmeurs, vous trouverez :\n\nUn √©diteur de texte am√©lior√© pour √©crire votre code, avec des fonctionnalit√©s comme la coloration syntaxique qui rend le code plus lisible.\nUn compilateur qui transforme votre code en instructions que l‚Äôordinateur peut comprendre.\nUn d√©bogueur pour trouver et corriger les erreurs, tel un d√©tective num√©rique.\nDes outils d‚Äôautomatisation qui effectuent des t√¢ches r√©p√©titives, comme un assistant virtuel pour le codage.\nL‚Äôacc√®s √† la documentation des diff√©rentes librairies.\n\nCes outils int√©gr√©s permettent aux d√©veloppeurs de travailler plus efficacement, en passant moins de temps √† jongler entre diff√©rentes applications et plus de temps √† produire du code.\nVoici quelques options populaires :\n\nPyCharm : C‚Äôest un des outils les plus utilis√©s dans l‚Äôindustrie. Il offre une multitude de fonctionnalit√©s comme l‚Äôautocompl√©tion intelligente et le d√©bogage int√©gr√©, id√©al pour les grands projets. Cepednant, cet outil peut √™tre assez gourmand en m√©moire et en CPU.\nVisual Studio Code : Gratuit, l√©ger mais puissant, il est personnalisable avec des extensions pour Python.\nSpyder : Logiciel libre et gratuit, orient√© vers les applications scientifiques.\nJupyter Notebooks : Imaginez un cahier interactif pour le code. Id√©al pour l‚Äôanalyse de donn√©es et l‚Äôapprentissage, il permet de m√©langer code, texte et visualisations. Des services gratuits dans le cloud sont disponibles comme Google Colab et Kaggle. Ces environnements sont n√©anmoins moins appropri√©es pour des grands projets et le d√©bogage.\nSublime Text : C‚Äôest comme un stylo √©l√©gant et rapide. L√©ger et rapide, il est appr√©ci√© pour sa simplicit√© et sa vitesse. Le choix d√©pend de vos besoins, que vous soyez d√©butant ou d√©veloppeur chevronn√©. L‚Äôimportant est de trouver l‚Äô√©diteur qui vous convient le mieux pour coder confortablement.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction au langage Python</span>"
    ]
  },
  {
    "objectID": "00-PriseEnMainPython.html#bonnes-pratiques",
    "href": "00-PriseEnMainPython.html#bonnes-pratiques",
    "title": "1¬† Introduction au langage Python",
    "section": "1.3 Bonnes pratiques",
    "text": "1.3 Bonnes pratiques\nPython est un langage tr√®s dynamique, qui √©volue constamment. Il est fortement conseill√© d‚Äôutiliser des environnements virtuels pour g√©rer vos diff√©rentes librairies. Voici quelques bonnes pratiques √† suivre :\n\nN‚Äôinstallez par la derni√®re version de Python : installez toujours une version ou deux qui pr√©c√®de la derni√®re version. Les versions trop r√©centes peuvent √™tre instables. La version de python d√©sir√©e peut √™tre sp√©cifi√©e au moment de la cr√©ation d‚Äôun environnement virtuel (voir plus bas).\nUtilisez des environnements virtuels : Pensez-y comme √† des compartiments s√©par√©es pour chaque projet. Cela √©vite les conflits entre les diff√©rentes versions de biblioth√®ques et garde votre syst√®me propre.\nV√©rifiez l‚Äôinstallation : Apr√®s l‚Äôinstallation, ouvrez un terminal et tapez python --version pour vous assurer que tout fonctionne correctement.\n\n\n1.3.1 Cr√©ation d‚Äôun environnement virtuel\nIl y a deux fa√ßons d‚Äôinstaller environnement virtuel selon votre distribution de Python:\n\nOption 1 : vous utilisez Anaconda ou Miniconda, dans ce cas la commande conda est utilis√©e pour cr√©er un environnement test avec Python 3.10:\n\nconda env -n test python=3.10\nconda activate test\n\nOption 2 : vous utilisez CPython\n\nconda env -n test python=3.10\nconda activate test\nNote: si vous utiliser des notebook jupyter, vous avez d√©j√† un environnement virtuel qui contient le serveur jupyter.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction au langage Python</span>"
    ]
  },
  {
    "objectID": "00-PriseEnMainPython.html#les-structures-de-base",
    "href": "00-PriseEnMainPython.html#les-structures-de-base",
    "title": "1¬† Introduction au langage Python",
    "section": "1.4 Les structures de base",
    "text": "1.4 Les structures de base\nIl y a essentiellement deux structures de donn√©es que Python manipule : les listes et les dictionnaires.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction au langage Python</span>"
    ]
  },
  {
    "objectID": "00-PriseEnMainPython.html#les-listes",
    "href": "00-PriseEnMainPython.html#les-listes",
    "title": "1¬† Introduction au langage Python",
    "section": "1.5 Les listes",
    "text": "1.5 Les listes\nLes listes sont comme des boites extensibles o√π vous pouvez ranger diff√©rents types d‚Äôobjets :\n\nRepr√©sent√©es par des crochets : [1, 2, 3, \"python\"].\nOrdonn√©es et modifiables (mutables), vous pouvez r√©cup√©rer une valeur par sa position avec [].\nPermettent les doublons (deux fois la m√™me valeur).\nId√©ales pour stocker des collections d‚Äô√©l√©ments que vous voulez modifier\n\n\n1.5.1 Les tuples\nLes tuples sont similaires aux listes, mais les bo√Ætes sont scell√©es :\n\nRepr√©sent√©s par des parenth√®ses : (1, 2, 3, \"python\").\nOrdonn√©s mais non modifiables (immutables).\nPermettent les doublons.\nSouvent utilis√© pour stocker des donn√©es qui ne doivent pas changer (comme des param√®tres).\n\n\n\n1.5.2 Les ensembles (Sets)\nLes ensembles sont comme des boites magiques qui ne gardent qu‚Äôun exemplaire de chaque objet :\n\nRepr√©sent√©s par des accolades : {1, 2, 3}.\nNon ordonn√©s et modifiables.\nN‚Äôautorisent pas les doublons.\nUtiles pour √©liminer les doublons et effectuer des op√©rations math√©matiques sur des ensembles.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction au langage Python</span>"
    ]
  },
  {
    "objectID": "00-PriseEnMainPython.html#dictionnaires",
    "href": "00-PriseEnMainPython.html#dictionnaires",
    "title": "1¬† Introduction au langage Python",
    "section": "1.6 Dictionnaires",
    "text": "1.6 Dictionnaires\nLes dictionnaires sont comme des boites avec des √©tiquettes sur chcune d‚Äôelle :\n\nRepr√©sent√©s par des accolades avec des paires cl√©-valeur : {\"nom\": \"Python\", \"ann√©e\": 1991}.\nNon ordonn√©s et modifiables.\nLes cl√©s doivent √™tre uniques, mais les valeurs peuvent √™tre dupliqu√©es\nUtiles pour stocker des donn√©es associatives ou pour cr√©er des tables de recherche rapide",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction au langage Python</span>"
    ]
  },
  {
    "objectID": "00-PriseEnMainPython.html#programmation-objet",
    "href": "00-PriseEnMainPython.html#programmation-objet",
    "title": "1¬† Introduction au langage Python",
    "section": "1.7 Programmation objet",
    "text": "1.7 Programmation objet\nLa programmation orient√©e objet (POO) en Python est comme construire avec des blocs LEGO. Chaque objet est un bloc LEGO avec ses propres caract√©ristiques (attributs) et capacit√©s (m√©thodes). Les classes sont les plans pour cr√©er ces blocs. Par exemple, une classe ‚ÄúVoiture‚Äù pourrait avoir des attributs comme ‚Äúcouleur‚Äù et ‚Äúvitesse‚Äù, et des m√©thodes comme ‚Äúd√©marrer‚Äù et ‚Äúacc√©l√©rer‚Äù.\nPython rend la POO accessible avec des fonctionnalit√©s conviviales :\n\nEncapsulation : Comme emballer un cadeau, elle cache les d√©tails internes d‚Äôun objet.\nH√©ritage : Permet de cr√©er de nouvelles classes bas√©es sur des classes existantes, comme un enfant h√©ritant des traits de ses parents.\nPolymorphisme : Permet √† diff√©rents objets de r√©pondre au m√™me message de mani√®re unique, comme si diff√©rents animaux r√©pondaient diff√©remment √† ‚Äúfais du bruit‚Äù.\n\nCes caract√©ristiques font de Python un excellent choix pour apprendre et appliquer les concepts de la POO, rendant le code plus organis√© et r√©utilisable\n\n\n\n\n\nListe des packages utilis√©s dans ce chapitre\n\n\n\nPour importer et manipuler des fichiers g√©ographiques¬†:\n\nsf pour importer et manipuler des donn√©es vectorielles.\nterra pour importer et manipuler des donn√©es matricielles.\n\nPour construire des cartes et des graphiques¬†:\n\ntmap est certainement le meilleur package pour la cartographie.\nggplot2 pour construire des graphiques.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction au langage Python</span>"
    ]
  },
  {
    "objectID": "00-PriseEnMainPython.html#quiz-de-r√©vision-du-chapitre",
    "href": "00-PriseEnMainPython.html#quiz-de-r√©vision-du-chapitre",
    "title": "1¬† Introduction au langage Python",
    "section": "1.8 Quiz de r√©vision du chapitre",
    "text": "1.8 Quiz de r√©vision du chapitre",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction au langage Python</span>"
    ]
  },
  {
    "objectID": "00-PriseEnMainPython.html#sec-016",
    "href": "00-PriseEnMainPython.html#sec-016",
    "title": "1¬† Introduction au langage Python",
    "section": "1.9 Cahier de r√©vision (notebook)",
    "text": "1.9 Cahier de r√©vision (notebook)\n\n\n\n\n\nNotebook 1. √Ä compl√©ter \n\n\n\n# ...\n# √† compl√©ter",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction au langage Python</span>"
    ]
  },
  {
    "objectID": "01-ImportationManipulationImages.html",
    "href": "01-ImportationManipulationImages.html",
    "title": "2¬† Importation et manipulation de donn√©es spatiales",
    "section": "",
    "text": "2.1 Bases de Quarto‚Ä¶\nVoici comment faire une liste¬†:\nVoici comment int√©grer des √©quations LaTeX. La formule de la distance euclidienne (√©quation¬†2.2). Pour √©crire directement une √©quation dans le texte, il suffit de \\(E = mc^2\\).\n\\[\nd_{ij} = 2R \\cdot \\text{ arcsin} \\left( \\sqrt{\\text{sin}^2 \\left( \\frac{\\delta _i - \\delta _j}{2} \\right) + \\text{cos }\\delta _i \\cdot \\text{cos }\\delta _j \\cdot \\text{sin}^2 \\left( \\frac{\\phi _i - \\phi _j}{2} \\right)} \\right)\n\\tag{2.1}\\]\n\\[\nd_{ij} = \\sqrt{(x_i-x_j)^2+(y_i-y_j)^2}\n\\tag{2.2}\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Importation et manipulation de donn√©es spatiales</span>"
    ]
  },
  {
    "objectID": "01-ImportationManipulationImages.html#sec-010",
    "href": "01-ImportationManipulationImages.html#sec-010",
    "title": "2¬† Importation et manipulation de donn√©es spatiales",
    "section": "",
    "text": "texte en gras\ntexte en italique\n\nGras et italique\n\nR2 et NO2\nPetites majuscules\nPour un lien Web, D√©partement de g√©omatique appliqu√©e.\n\n\n\n\n\nInt√©grer une figure (image) et l‚Äôappeler dans le texte (figure¬†2.1). √Ä la figure¬†2.1, ‚Ä¶ Notez que la num√©rotation des figures, des tableaux, des √©quations est automatique.\n\n\n\n\n\n\n\nFigure¬†2.1: T√©l√©chargement de l‚Äôint√©gralit√© du livre\n\n\n\n\nLes r√©f√©rences sont au format BibTeX. Par exemple, vous pouvez les t√©l√©charger de Google Scholar et les int√©grer √† la fin du fichier references.bib. Voici comment int√©grer des r√©f√©rences (Mather et Koch 2022; Richards, Richards et al. 2022). Selon Ferdinand Boon et Guy Rochon (1992).",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Importation et manipulation de donn√©es spatiales</span>"
    ]
  },
  {
    "objectID": "01-ImportationManipulationImages.html#sec-011",
    "href": "01-ImportationManipulationImages.html#sec-011",
    "title": "2¬† Importation et manipulation de donn√©es spatiales",
    "section": "2.2 Importation d‚Äôimages",
    "text": "2.2 Importation d‚Äôimages\nLa premi√®re √©tape avant tout traitement est d‚Äôacc√©der √† la donn√©e image pour qu‚Äôelle soit manipul√©e par le programme Python. L‚Äôimagerie satellite pr√©sente certains d√©fis notamment en raison de la taille parfois tr√®s importante des images. Il existe maintenant certaines librairies, comme üîñXarray, qui on cherch√©es √† optimiser la lecture et l‚Äô√©criture de grandes images. Il est donc conseiller de toujours garder un oeil sur l‚Äôespace m√©moire occup√© par les variables Python reli√©es aux images. La librairie principale en g√©omatique qui va nous permettre d‚Äôimporter (et d‚Äôexporter) de l‚Äôimagerie est la librairie GDAL qui rassemble la plupart des formats sous forme de driver (ou pilote en fran√ßais).\nDans le domaine de la g√©omatique, il faut pr√™ter attention √† trois caract√©ristiques principales des images: 1. La matrice des donn√©es elle-m√™me qui contient les valeurs brutes des pixels. Cette matrice sera souvent un cube √† trois dimensions. En Python, ce cube sera le plus souvent un objet de la librairie üîñNumPy (voir section). 2. La dynamique des images c.√†.d le format de stockage des valeurs individuelles (octet, entier, double, etc.). Ce format d√©cide principalement de la r√©solution radiom√©trique et des valeurs minimales et maximales support√©es. 3. La m√©tadonn√©e qui va transporter l‚Äôinformation auxiliaire de l‚Äôimage comme les dimensions et la position de l‚Äôimage, la date, etc. Cette donn√©e auxiliaire prendra souvent la forme d‚Äôun dictionnaire Python.\nLes diff√©rents formats se distinguent principalement sur la mani√®re dont ces trois caract√©ristiques sont g√©r√©es.\n\n2.2.1 Formats des images\nIl existe maintenant de nombreux formats num√©riques pour la donn√©e de type image parfois appel√© donn√©e matricielle ou donn√©e raster. La librairie GDAL rassemble la plupart des formats matriciels rencontr√©s en g√©omatique (voir üîñRaster drivers ‚Äî GDAL documentation pour une liste compl√®te).\nOn peut distinguer deux grandes familles de format: 1. Les formats de type RVB issus de l‚Äôimagerie num√©rique grand publique comme üîñJPEG, png, etc. Ces formats ne supportent g√©n√©ralement que trois bandes au maximum (rouge, vert et bleu) et des valeurs de niveaux de gris entre 0 et 255 (format dit 8 bit). 2. Les g√©o-formats issus des domaines scientifiques ou techniques comme GeoTIFF, HDF5, etc. qui peuvent inclure plus que trois bandes et des dynamiques plus √©lev√©es (16 bit ou m√™me float).\nLes formats RVB restent tr√®s utilis√©s en Python notamment par les librairies dites de vision par ordinateur (Computer Vision) comme OpenCV et sickit-image ainsi que les grandes librairies en apprentissage profond (PyTorch, Tensorflow).\n\n\n\n\n\nInstallation de gdal dans un syst√®me Linux \n\n\n\nPour installer GDAL¬†:\n\n!apt-get update\n!apt-get install gdal-bin libgdal-dev\n\n\n\n2.2.1.1 Formats de type RVB\nLes premiers formats pour de l‚Äôimagerie √† une bande (monochrome) et √† trois bandes (image couleur rouge-vert-bleu) sont issus du domaine des sciences de l‚Äôordinateur. On trouvera, entre autres, les formats pbm, png et jpeg. Ces formats supportent peu de m√©tadonn√©es et sont plac√©es dans un ent√™te (header) tr√®s limit√©. Cependant, ces formats restent tr√®s populaires dans le domaine de la vision par ordinateur et sont tr√®s utilis√©s en apprentissage profond en particulier. Pour la lecture des images RVB, on peut utiliser les librairies Rasterio, PIL ou OpenCV.\n\n2.2.1.1.1 Lecture avec la librairie PIL\nLa librairie PIL retourne un objet de type PngImageFile, l‚Äôaffichage de l‚Äôimage se fait directement dans la cellule de sortie.\n\n\n\n\nBloc de code¬†2.1: Lecture d‚Äôune image en format PNG avec PIL\n\n\n!wget https://raw.githubusercontent.com/sfoucher/TraitementImagesPythonVol1/refs/heads/main/images/modis-aqua.PNG -O modis-aqua.PNG\nfrom PIL import Image\nimg = Image.open('modis-aqua.PNG')\nimg\n\n\n\n\n--2024-11-23 15:31:33--  https://raw.githubusercontent.com/sfoucher/TraitementImagesPythonVol1/refs/heads/main/images/modis-aqua.PNG\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 481097 (470K) [image/png]\nSaving to: ‚Äòmodis-aqua.PNG‚Äô\n\nmodis-aqua.PNG        0%[                    ]       0  --.-KB/s               modis-aqua.PNG       90%[=================&gt;  ] 423.11K  2.00MB/s               modis-aqua.PNG      100%[===================&gt;] 469.82K  2.09MB/s    in 0.2s    \n\n2024-11-23 15:31:34 (2.09 MB/s) - ‚Äòmodis-aqua.PNG‚Äô saved [481097/481097]\n\n\n\n\n\n\n\n\n\n\n\n\n2.2.1.1.2 Lecture avec la librairie OpenCV\nLa librairie OpenCV est aussi tr√®s populaire en vision par ordinateur. La fonction imread donne directement un objet de type NumPy en sortie.\n\n\n\n\nBloc de code¬†2.2: Lecture d‚Äôune image en format PNG avec OpenCV\n\n\n!wget https://raw.githubusercontent.com/sfoucher/TraitementImagesPythonVol1/refs/heads/main/images/modis-aqua.PNG -O modis-aqua.PNG\nimport cv2\nimg = cv2.imread('modis-aqua.PNG')\nimg\n\n\n\n\n\n\n2.2.1.1.3 Lecture avec la librairie RasterIO\nRien ne nous emp√™che de lire une image de format RVB avec RasterIO comme d√©crit dans (bloc¬†2.5). Vous noterez cependant les avertissements concernant l‚Äôabsence de g√©or√©f√©rence pour ce type d‚Äôimage.\n\n\n\n\nBloc de code¬†2.3: Lecture d‚Äôune image en format PNG avec OpenCV\n\n\n!wget https://raw.githubusercontent.com/sfoucher/TraitementImagesPythonVol1/refs/heads/main/images/modis-aqua.PNG -O modis-aqua.PNG\nimport rasterio\nimg= rasterio.open('modis-aqua.PNG')\nimg\n\n\n\n\n\n\n\n2.2.1.2 Le format GeoTiff\nLe format GeoTIFF est une extension du format TIFF (Tagged Image File Format) qui permet d‚Äôincorporer des m√©tadonn√©es g√©ospatiales directement dans un fichier image. D√©velopp√© initialement par Dr.¬†Niles Ritter au Jet Propulsion Laboratory de la NASA dans les ann√©es 1990, GeoTIFF est devenu un standard de facto pour le stockage et l‚Äô√©change d‚Äôimages g√©or√©f√©renc√©es dans les domaines de la t√©l√©d√©tection et des syst√®mes d‚Äôinformation g√©ographique (SIG). Ce format supporte plus que trois bandes aussi longtemps que ces bandes sont de m√™me dimension.\nLe format GeoTIFF est tr√®s utilis√© et est largement support√© par les biblioth√®ques et logiciels g√©ospatiaux, notamment GDAL (Geospatial Data Abstraction Library), qui offre des capacit√©s de lecture et d‚Äô√©criture pour ce format. Cette compatibilit√© √©tendue a contribu√© √† son adoption g√©n√©ralis√©e dans la communaut√© g√©ospatiale.\n\n2.2.1.2.1 Standardisation par l‚ÄôOGC\nLe standard GeoTIFF propos√© par l‚ÄôOpen Geospatial Consortium (OGC) en 2019 formalise et √©tend les sp√©cifications originales du format GeoTIFF, offrant une norme robuste pour l‚Äô√©change d‚Äôimages g√©or√©f√©renc√©es. Cette standardisation, connue sous le nom d‚ÄôOGC GeoTIFF 1.1 (2019), apporte plusieurs am√©liorations et clarifications importantes.\n\n\n\n2.2.1.3 Le format COG\nUne innovation r√©cente dans l‚Äô√©cosyst√®me GeoTIFF est le format Cloud Optimized GeoTIFF (COG), con√ßu pour faciliter l‚Äôutilisation de fichiers GeoTIFF h√©berg√©s sur des serveurs web HTTP. Le COG permet aux utilisateurs et aux logiciels d‚Äôacc√©der √† des parties sp√©cifiques du fichier sans avoir √† le t√©l√©charger enti√®rement, ce qui est particuli√®rement utile pour les applications bas√©es sur le cloud.\n\n\n\n2.2.2 M√©tadonn√©es des images\nLa mani√®re la plus directe d‚Äôacc√©der √† la m√©tadonn√©e d‚Äôune image est d‚Äôutiliser les commandes üîñrio info de la librairie Rasterio ou gdalinfo de la librairie gdal. Le r√©sultat est imprim√© dans la sortie standard ou sous forme d‚Äôun dictionnaire Python.\n\n\n\n\nBloc de code¬†2.4: Lecture d‚Äôune image en format PNG avec OpenCV\n\n\n!wget https://github.com/sfoucher/TraitementImagesPythonVol1/raw/refs/heads/main/data/chapitre01/subset_RGBNIR_of_S2A_MSIL2A_20240625T153941_N0510_R011_T18TYR_20240625T221903.tif -O RGBNIR_of_S2A.tif\n\n!gdalinfo RGBNIR_of_S2A.tif\n\n\n\n\n\n\n\n\nBloc de code¬†2.5: Lecture d‚Äôune image en format PNG avec OpenCV\n\n\n!wget https://github.com/sfoucher/TraitementImagesPythonVol1/raw/refs/heads/main/data/chapitre01/subset_RGBNIR_of_S2A_MSIL2A_20240625T153941_N0510_R011_T18TYR_20240625T221903.tif -O RGBNIR_of_S2A.tif\n\n!rio info RGBNIR_of_S2A.tif --indent 2 --verbose\n\n\n\n\n--2024-11-23 15:31:34--  https://github.com/sfoucher/TraitementImagesPythonVol1/raw/refs/heads/main/data/chapitre01/subset_RGBNIR_of_S2A_MSIL2A_20240625T153941_N0510_R011_T18TYR_20240625T221903.tif\nResolving github.com (github.com)... 140.82.114.4\nConnecting to github.com (github.com)|140.82.114.4|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://media.githubusercontent.com/media/sfoucher/TraitementImagesPythonVol1/refs/heads/main/data/chapitre01/subset_RGBNIR_of_S2A_MSIL2A_20240625T153941_N0510_R011_T18TYR_20240625T221903.tif [following]\n--2024-11-23 15:31:34--  https://media.githubusercontent.com/media/sfoucher/TraitementImagesPythonVol1/refs/heads/main/data/chapitre01/subset_RGBNIR_of_S2A_MSIL2A_20240625T153941_N0510_R011_T18TYR_20240625T221903.tif\nResolving media.githubusercontent.com (media.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\nConnecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 52585418 (50M) [image/tiff]\nSaving to: ‚ÄòRGBNIR_of_S2A.tif‚Äô\n\nRGBNIR_of_S2A.tif     0%[                    ]       0  --.-KB/s               RGBNIR_of_S2A.tif     0%[                    ] 488.00K  2.38MB/s               RGBNIR_of_S2A.tif     1%[                    ] 922.81K  2.23MB/s               RGBNIR_of_S2A.tif     2%[                    ]   1.49M  2.45MB/s               RGBNIR_of_S2A.tif     4%[                    ]   2.03M  2.49MB/s               RGBNIR_of_S2A.tif     5%[&gt;                   ]   2.73M  2.68MB/s               RGBNIR_of_S2A.tif     6%[&gt;                   ]   3.46M  2.68MB/s               RGBNIR_of_S2A.tif     8%[&gt;                   ]   4.20M  2.81MB/s               RGBNIR_of_S2A.tif     9%[&gt;                   ]   5.01M  2.96MB/s               RGBNIR_of_S2A.tif    11%[=&gt;                  ]   5.88M  3.10MB/s               RGBNIR_of_S2A.tif    13%[=&gt;                  ]   6.90M  3.29MB/s               RGBNIR_of_S2A.tif    15%[==&gt;                 ]   7.95M  3.46MB/s               RGBNIR_of_S2A.tif    17%[==&gt;                 ]   8.95M  3.58MB/s               RGBNIR_of_S2A.tif    19%[==&gt;                 ]   9.84M  3.64MB/s               RGBNIR_of_S2A.tif    21%[===&gt;                ]  10.93M  3.76MB/s               RGBNIR_of_S2A.tif    23%[===&gt;                ]  11.93M  3.84MB/s    eta 10s    RGBNIR_of_S2A.tif    26%[====&gt;               ]  13.12M  4.05MB/s    eta 10s    RGBNIR_of_S2A.tif    28%[====&gt;               ]  14.25M  4.25MB/s    eta 10s    RGBNIR_of_S2A.tif    30%[=====&gt;              ]  15.32M  4.40MB/s    eta 10s    RGBNIR_of_S2A.tif    32%[=====&gt;              ]  16.54M  4.67MB/s    eta 10s    RGBNIR_of_S2A.tif    35%[======&gt;             ]  17.78M  4.82MB/s    eta 7s     RGBNIR_of_S2A.tif    37%[======&gt;             ]  19.03M  4.97MB/s    eta 7s     RGBNIR_of_S2A.tif    40%[=======&gt;            ]  20.10M  5.16MB/s    eta 7s     RGBNIR_of_S2A.tif    42%[=======&gt;            ]  21.46M  5.36MB/s    eta 7s     RGBNIR_of_S2A.tif    45%[========&gt;           ]  22.59M  5.44MB/s    eta 7s     RGBNIR_of_S2A.tif    47%[========&gt;           ]  24.03M  5.64MB/s    eta 6s     RGBNIR_of_S2A.tif    50%[=========&gt;          ]  25.43M  5.73MB/s    eta 6s     RGBNIR_of_S2A.tif    53%[=========&gt;          ]  26.81M  5.81MB/s    eta 6s     RGBNIR_of_S2A.tif    56%[==========&gt;         ]  28.46M  6.10MB/s    eta 6s     RGBNIR_of_S2A.tif    59%[==========&gt;         ]  29.93M  6.20MB/s    eta 6s     RGBNIR_of_S2A.tif    62%[===========&gt;        ]  31.40M  6.32MB/s    eta 4s     RGBNIR_of_S2A.tif    65%[============&gt;       ]  32.78M  6.43MB/s    eta 4s     RGBNIR_of_S2A.tif    68%[============&gt;       ]  34.26M  6.53MB/s    eta 4s     RGBNIR_of_S2A.tif    71%[=============&gt;      ]  35.70M  6.60MB/s    eta 4s     RGBNIR_of_S2A.tif    74%[=============&gt;      ]  37.13M  6.70MB/s    eta 4s     RGBNIR_of_S2A.tif    77%[==============&gt;     ]  38.62M  6.80MB/s    eta 2s     RGBNIR_of_S2A.tif    80%[===============&gt;    ]  40.17M  6.88MB/s    eta 2s     RGBNIR_of_S2A.tif    83%[===============&gt;    ]  41.73M  6.97MB/s    eta 2s     RGBNIR_of_S2A.tif    86%[================&gt;   ]  43.37M  7.17MB/s    eta 2s     RGBNIR_of_S2A.tif    89%[================&gt;   ]  45.09M  7.30MB/s    eta 2s     RGBNIR_of_S2A.tif    92%[=================&gt;  ]  46.60M  7.35MB/s    eta 1s     RGBNIR_of_S2A.tif    96%[==================&gt; ]  48.21M  7.43MB/s    eta 1s     RGBNIR_of_S2A.tif    99%[==================&gt; ]  49.84M  7.50MB/s    eta 1s     RGBNIR_of_S2A.tif   100%[===================&gt;]  50.15M  7.49MB/s    in 8.6s    \n\n2024-11-23 15:31:44 (5.80 MB/s) - ‚ÄòRGBNIR_of_S2A.tif‚Äô saved [52585418/52585418]\n\nWARNING:rasterio._env:CPLE_AppDefined in RGBNIR_of_S2A.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWARNING:rasterio._env:CPLE_AppDefined in /home/sfoucher/DEV/TraitementImagesPythonVol1/RGBNIR_of_S2A.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\nWARNING:rasterio._env:CPLE_AppDefined in TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n{\n  \"blockysize\": 1926,\n  \"bounds\": [\n    731780.0,\n    5021540.0,\n    752520.0,\n    5040800.0\n  ],\n  \"checksum\": [\n    18623,\n    42114,\n    31774,\n    54171\n  ],\n  \"colorinterp\": [\n    \"gray\",\n    \"undefined\",\n    \"undefined\",\n    \"undefined\"\n  ],\n  \"count\": 4,\n  \"crs\": \"EPSG:32618\",\n  \"descriptions\": [\n    null,\n    null,\n    null,\n    null\n  ],\n  \"driver\": \"GTiff\",\n  \"dtype\": \"uint16\",\n  \"height\": 1926,\n  \"indexes\": [\n    1,\n    2,\n    3,\n    4\n  ],\n  \"interleave\": \"band\",\n  \"lnglat\": [\n    -71.90643373271799,\n    45.39214029576973\n  ],\n  \"mask_flags\": [\n    [\n      \"all_valid\"\n    ],\n    [\n      \"all_valid\"\n    ],\n    [\n      \"all_valid\"\n    ],\n    [\n      \"all_valid\"\n    ]\n  ],\n  \"nodata\": null,\n  \"res\": [\n    10.0,\n    10.0\n  ],\n  \"shape\": [\n    1926,\n    2074\n  ],\n  \"stats\": [\n    {\n      \"max\": 15104.0,\n      \"mean\": 1426.6252674911955,\n      \"min\": 86.0,\n      \"std\": 306.56427126941827\n    },\n    {\n      \"max\": 14352.0,\n      \"mean\": 1669.6050060032185,\n      \"min\": 1139.0,\n      \"std\": 310.9193578763909\n    },\n    {\n      \"max\": 15280.0,\n      \"mean\": 1471.3923473735545,\n      \"min\": 706.0,\n      \"std\": 385.4465459301353\n    },\n    {\n      \"max\": 15642.0,\n      \"mean\": 4393.944850249993,\n      \"min\": 1067.0,\n      \"std\": 1037.9339397279546\n    }\n  ],\n  \"tiled\": false,\n  \"transform\": [\n    10.0,\n    0.0,\n    731780.0,\n    0.0,\n    -10.0,\n    5040800.0,\n    0.0,\n    0.0,\n    1.0\n  ],\n  \"units\": [\n    null,\n    null,\n    null,\n    null\n  ],\n  \"width\": 2074\n}",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Importation et manipulation de donn√©es spatiales</span>"
    ]
  },
  {
    "objectID": "01-ImportationManipulationImages.html#sec-012",
    "href": "01-ImportationManipulationImages.html#sec-012",
    "title": "2¬† Importation et manipulation de donn√©es spatiales",
    "section": "2.5 Importation de donn√©es vectorielles",
    "text": "2.5 Importation de donn√©es vectorielles\n\n2.5.1 Importation d‚Äôun fichier shapefile\n\n\n2.5.2 Importation d‚Äôune couche dans un GeoPackage\n\n\n2.5.3 Importation d‚Äôune couche dans une geodatabase d‚ÄôESRI\n\n\n2.5.4 Importation d‚Äôun fichier shapefile",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Importation et manipulation de donn√©es spatiales</span>"
    ]
  },
  {
    "objectID": "01-ImportationManipulationImages.html#sec-013",
    "href": "01-ImportationManipulationImages.html#sec-013",
    "title": "2¬† Importation et manipulation de donn√©es spatiales",
    "section": "2.4 Donn√©es en g√©oscience",
    "text": "2.4 Donn√©es en g√©oscience\nCalibration, unit√©s, donn√©es manquantes, donn√©es √©parses.\nnetcdf, xarray, GRIB.\nDonn√©es m√©t√©os, exemple avec SWOT.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Importation et manipulation de donn√©es spatiales</span>"
    ]
  },
  {
    "objectID": "01-ImportationManipulationImages.html#sec-014",
    "href": "01-ImportationManipulationImages.html#sec-014",
    "title": "2¬† Importation et manipulation de donn√©es spatiales",
    "section": "2.6 Manipulation de donn√©es vectorielles",
    "text": "2.6 Manipulation de donn√©es vectorielles\n\n2.6.1 Requ√™tes attributaires",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Importation et manipulation de donn√©es spatiales</span>"
    ]
  },
  {
    "objectID": "01-ImportationManipulationImages.html#sec-015",
    "href": "01-ImportationManipulationImages.html#sec-015",
    "title": "2¬† Importation et manipulation de donn√©es spatiales",
    "section": "2.7 Quiz de r√©vision du chapitre",
    "text": "2.7 Quiz de r√©vision du chapitre",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Importation et manipulation de donn√©es spatiales</span>"
    ]
  },
  {
    "objectID": "01-ImportationManipulationImages.html#sec-016",
    "href": "01-ImportationManipulationImages.html#sec-016",
    "title": "2¬† Importation et manipulation de donn√©es spatiales",
    "section": "2.8 Exercices de r√©vision",
    "text": "2.8 Exercices de r√©vision\n\n\n\n\n\nExercice 1. √Ä compl√©ter\n\n\n\n# ...\n# √† compl√©ter\n\nCorrection √† la ?sec-08011.\n\n\n\n\n\n\n\nExercice 2. √Ä compl√©ter\n\n\n\n# ...\n# √† compl√©ter\n\nCorrection √† la ?sec-08012.\n\n\n\n\n\n\n\nExercice 3. √Ä compl√©ter\n\n\n\n# ...\n# √† compl√©ter\n\nCorrection √† la ?sec-08013.\n\n\n\n\n\n\nBonn, Ferdinand et Guy Rochon. 1992. Pr√©cis de t√©l√©d√©tection. Volume 1 : principes et m√©thodes. Presses de l‚Äôuniversit√© du Qu√©bec; Agence universitaire de la Francophonie.\n\n\nHarris, Millman, C. R. 2020. ¬´¬†Array programming with NumPy.¬†¬ª Nature: 357‚Äë362. https://doi.org/10.1038/s41586-020-2649-2.\n\n\nMather, Paul M et Magaly Koch. 2022. Computer processing of remotely-sensed images. John Wiley & Sons.\n\n\nOGC. 2019. ¬´¬†OGC GeoTIFF Standard.¬†¬ª https://docs.ogc.org/is/19-008r4/19-008r4.html/.\n\n\nRichards, John A, John A Richards et al. 2022. Remote sensing digital image analysis. Vol. 5. Springer.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Importation et manipulation de donn√©es spatiales</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Bibliographie",
    "section": "",
    "text": "Bonn, Ferdinand et Guy Rochon. 1992. Pr√©cis de t√©l√©d√©tection. Volume\n1 : principes et m√©thodes. Presses de l‚Äôuniversit√© du Qu√©bec;\nAgence universitaire de la Francophonie.\n\n\nHarris, Millman, C. R. 2020. ¬´¬†Array programming with\nNumPy.¬†¬ª Nature: 357‚Äë362. https://doi.org/10.1038/s41586-020-2649-2.\n\n\nMather, Paul M et Magaly Koch. 2022. Computer processing of\nremotely-sensed images. John Wiley & Sons.\n\n\nOGC. 2019. ¬´¬†OGC GeoTIFF Standard.¬†¬ª https://docs.ogc.org/is/19-008r4/19-008r4.html/.\n\n\nRichards, John A, John A Richards et al. 2022. Remote sensing\ndigital image analysis. Vol. 5. Springer.",
    "crumbs": [
      "Bibliographie"
    ]
  }
]